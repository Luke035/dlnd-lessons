{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Net Preprocessing\n",
    "Notebook di processamento delle immagini di Image Net. Obiettivo è realizzare un batch input che, sfruttando il meccasnismo a code descritto in <a href=https://www.tensorflow.org/programmers_guide/reading_data>Tensorflow</a>, fornisca batch della dimensione desiderata per il numero di epoche desiderato.\n",
    "\n",
    "Viene inoltre sfruttanto l'algoritmo di <a href=https://github.com/tensorflow/models/blob/master/slim/preprocessing/inception_preprocessing.py>Inception preprocessing</a> per fornire in input immagini della dimensione corretta con le correzioni preaddestramento fornite da Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf /tmp/ImageNetTrainTransfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from PIL import Image\n",
    "#Inception preprocessing code from https://github.com/tensorflow/models/blob/master/slim/preprocessing/inception_preprocessing.py\n",
    "#useful to maintain training dimension\n",
    "from utils import inception_preprocessing\n",
    "import sys\n",
    "\n",
    "#from inception import inception\n",
    "'''\n",
    "Uso di slim e nets_factory (come per SLIM Tensorflow https://github.com/tensorflow/models/blob/master/slim/train_image_classifier.py)\n",
    "per il ripristino della rete. \n",
    "\n",
    "Le reti devono essere censite in nets_factory (v. struttura file nella directory di questo notebook)\n",
    "'''\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "from nets import nets_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Global Variables\n",
    "IMAGE_NET_ROOT_PATH = '/home/carnd/transfer-learning-utils/tiny-imagenet-200/'\n",
    "#IMAGE_NET_ROOT_PATH = '/data/lgrazioli/'\n",
    "IMAGE_NET_LABELS_PATH = IMAGE_NET_ROOT_PATH + 'words.txt'\n",
    "IMAGE_NET_TRAIN_PATH = IMAGE_NET_ROOT_PATH + 'train/'\n",
    "TRAINING_CHECKPOINT_DIR = '/tmp/ImageNetTrainTransfer'\n",
    "#Transfer learning CHECKPOINT PATH\n",
    "#File ckpt della rete\n",
    "CHECKPOINT_PATH = '/home/carnd/transfer-learning-utils/inception_v4.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Lettura file words di ImageNet\n",
    "Lettura del file words di ImageNet come PandaDF. A ogni id (cartella che contiene immagini per le classi fornite) vengono assegnati i label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/__main__.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n00001740</td>\n",
       "      <td>entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n00001930</td>\n",
       "      <td>physical entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n00002137</td>\n",
       "      <td>abstraction, abstract entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n00002452</td>\n",
       "      <td>thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n00002684</td>\n",
       "      <td>object, physical object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                        labels\n",
       "0  n00001740                        entity\n",
       "1  n00001930               physical entity\n",
       "2  n00002137  abstraction, abstract entity\n",
       "3  n00002452                         thing\n",
       "4  n00002684       object, physical object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading label file as Panda dataframe\n",
    "labels_df = pd.read_csv(IMAGE_NET_LABELS_PATH, sep='\\\\t', header=None, names=['id','labels'])\n",
    "labels_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        82115\n",
       "labels    82114\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Aggiunta colonna di lunghezza del label (quante classi contiene ogni label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#new_labels = []\n",
    "labels_lengths = []\n",
    "for idx, row in labels_df.iterrows():\n",
    "    #Convertire a stringa perchè alcuni sono float\n",
    "    current_labels = tuple(str(row['labels']).split(','))\n",
    "    #new_labels.append(current_labels)\n",
    "    labels_lengths.append(len(current_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels_df['labels_length'] = labels_lengths\n",
    "labels_indices = [idx for idx, _ in labels_df.iterrows()]\n",
    "labels_df['indices'] = labels_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_length</th>\n",
       "      <th>indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n00001740</td>\n",
       "      <td>entity</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n00001930</td>\n",
       "      <td>physical entity</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n00002137</td>\n",
       "      <td>abstraction, abstract entity</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n00002452</td>\n",
       "      <td>thing</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n00002684</td>\n",
       "      <td>object, physical object</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n00003553</td>\n",
       "      <td>whole, unit</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n00003993</td>\n",
       "      <td>congener</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n00004258</td>\n",
       "      <td>living thing, animate thing</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n00004475</td>\n",
       "      <td>organism, being</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n00005787</td>\n",
       "      <td>benthos</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>n00005930</td>\n",
       "      <td>dwarf</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>n00006024</td>\n",
       "      <td>heterotroph</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>n00006150</td>\n",
       "      <td>parent</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>n00006269</td>\n",
       "      <td>life</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>n00006400</td>\n",
       "      <td>biont</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>n00006484</td>\n",
       "      <td>cell</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>n00007347</td>\n",
       "      <td>causal agent, cause, causal agency</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>n00007846</td>\n",
       "      <td>person, individual, someone, somebody, mortal,...</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>n00015388</td>\n",
       "      <td>animal, animate being, beast, brute, creature,...</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>n00017222</td>\n",
       "      <td>plant, flora, plant life</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             labels  \\\n",
       "0   n00001740                                             entity   \n",
       "1   n00001930                                    physical entity   \n",
       "2   n00002137                       abstraction, abstract entity   \n",
       "3   n00002452                                              thing   \n",
       "4   n00002684                            object, physical object   \n",
       "5   n00003553                                        whole, unit   \n",
       "6   n00003993                                           congener   \n",
       "7   n00004258                        living thing, animate thing   \n",
       "8   n00004475                                    organism, being   \n",
       "9   n00005787                                            benthos   \n",
       "10  n00005930                                              dwarf   \n",
       "11  n00006024                                        heterotroph   \n",
       "12  n00006150                                             parent   \n",
       "13  n00006269                                               life   \n",
       "14  n00006400                                              biont   \n",
       "15  n00006484                                               cell   \n",
       "16  n00007347                 causal agent, cause, causal agency   \n",
       "17  n00007846  person, individual, someone, somebody, mortal,...   \n",
       "18  n00015388  animal, animate being, beast, brute, creature,...   \n",
       "19  n00017222                           plant, flora, plant life   \n",
       "\n",
       "    labels_length  indices  \n",
       "0               1        0  \n",
       "1               1        1  \n",
       "2               2        2  \n",
       "3               1        3  \n",
       "4               2        4  \n",
       "5               2        5  \n",
       "6               1        6  \n",
       "7               2        7  \n",
       "8               2        8  \n",
       "9               1        9  \n",
       "10              1       10  \n",
       "11              1       11  \n",
       "12              1       12  \n",
       "13              1       13  \n",
       "14              1       14  \n",
       "15              1       15  \n",
       "16              3       16  \n",
       "17              6       17  \n",
       "18              6       18  \n",
       "19              3       19  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train DF\n",
    "Panda Dataframe che contiene i path di tutte le immagini, la relativa classe, id dell'immagine e classe. La classe viene ottenuta tramite lookup su labels_df (<b>tale operazione pesa molto in termini di tempi di esecuzione</b>)\n",
    "\n",
    "<b>Può richiedere del tempo. Per lanciare su un campione si può bloccare a un determinato valore di idx</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label n09332890\n",
      "Processing label n04275548\n",
      "Processing label n02165456\n",
      "Processing label n03179701\n",
      "Processing label n04597913\n",
      "Processing label n01855672\n",
      "Processing label n02129165\n",
      "Processing label n07720875\n",
      "Processing label n03733131\n",
      "Processing label n02950826\n",
      "Processing label n01644900\n",
      "im_path         5500\n",
      "class           5500\n",
      "im_class_id     5500\n",
      "target_label    5500\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>im_path</th>\n",
       "      <th>class</th>\n",
       "      <th>im_class_id</th>\n",
       "      <th>target_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/carnd/transfer-learning-utils/tiny-image...</td>\n",
       "      <td>n09332890</td>\n",
       "      <td>347</td>\n",
       "      <td>lakeside, lakeshore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/carnd/transfer-learning-utils/tiny-image...</td>\n",
       "      <td>n09332890</td>\n",
       "      <td>188</td>\n",
       "      <td>lakeside, lakeshore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/carnd/transfer-learning-utils/tiny-image...</td>\n",
       "      <td>n09332890</td>\n",
       "      <td>16</td>\n",
       "      <td>lakeside, lakeshore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/carnd/transfer-learning-utils/tiny-image...</td>\n",
       "      <td>n09332890</td>\n",
       "      <td>116</td>\n",
       "      <td>lakeside, lakeshore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/carnd/transfer-learning-utils/tiny-image...</td>\n",
       "      <td>n09332890</td>\n",
       "      <td>61</td>\n",
       "      <td>lakeside, lakeshore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             im_path      class im_class_id  \\\n",
       "0  /home/carnd/transfer-learning-utils/tiny-image...  n09332890         347   \n",
       "1  /home/carnd/transfer-learning-utils/tiny-image...  n09332890         188   \n",
       "2  /home/carnd/transfer-learning-utils/tiny-image...  n09332890          16   \n",
       "3  /home/carnd/transfer-learning-utils/tiny-image...  n09332890         116   \n",
       "4  /home/carnd/transfer-learning-utils/tiny-image...  n09332890          61   \n",
       "\n",
       "          target_label  \n",
       "0  lakeside, lakeshore  \n",
       "1  lakeside, lakeshore  \n",
       "2  lakeside, lakeshore  \n",
       "3  lakeside, lakeshore  \n",
       "4  lakeside, lakeshore  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths = []\n",
    "for idx, label_dir in enumerate(os.listdir(IMAGE_NET_TRAIN_PATH)):\n",
    "    image_dir_path = IMAGE_NET_TRAIN_PATH + label_dir + '/images/'\n",
    "    print(\"Processing label {0}\".format(label_dir))\n",
    "    for image in os.listdir(image_dir_path):\n",
    "        #Estrazione class_id\n",
    "        class_id = image.split('.')[0].split('_')[0]\n",
    "        #Lookup su labels df\n",
    "        target_label = labels_df[labels_df['id'] == class_id] #=> pass to tf.nn.one_hot\n",
    "        #Estrazione del label\n",
    "        target_label = target_label['labels'].values[0]\n",
    "        train_paths.append((image_dir_path + image, \n",
    "                            class_id,\n",
    "                            image.split('.')[0].split('_')[1],\n",
    "                            target_label\n",
    "                           ))\n",
    "    if idx == 10:\n",
    "        break\n",
    "train_df = pd.DataFrame(train_paths, columns=['im_path','class', 'im_class_id', 'target_label'])\n",
    "print(train_df.count())\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Pulizia delle immagini che non sono nel formato desiderato da inception_preprocessing (3 canali). \n",
    "<b>Operazione lunga!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5480 imagesNew size: 5434\n",
      "Removed 66 images\n"
     ]
    }
   ],
   "source": [
    "#Remove black and white images\n",
    "uncorrect_images = 0\n",
    "#Salvataggio indici di immagini da eliminare\n",
    "to_remove_indexes = []\n",
    "for idx, record in train_df.iterrows():\n",
    "    #Leggo immagine come np.array\n",
    "    im_array = np.array(Image.open(record['im_path']))\n",
    "    #Se non ha 3 canali la aggiungo a quelle da eliminare\n",
    "    if im_array.shape[-1] != 3:\n",
    "        uncorrect_images += 1\n",
    "        to_remove_indexes.append(idx)\n",
    "    if idx % 20 == 0:\n",
    "        sys.stdout.write(\"\\rProcessed {0} images\".format(idx))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "#Rimozione righe identificate\n",
    "train_df = train_df.drop(train_df.index[to_remove_indexes])\n",
    "\n",
    "print(\"New size: {0}\".format(len(train_df)))\n",
    "print(\"Removed {0} images\".format(uncorrect_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5434\n"
     ]
    }
   ],
   "source": [
    "#Eventuale campionamento da passare al generatore input\n",
    "example_file_list = list(train_df.im_path)\n",
    "print(len(example_file_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Definizione dizionario dei labels\n",
    "{label: indice}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76003"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict = {}\n",
    "unique_labels = set(labels_df['labels'])\n",
    "for idx, target in enumerate(unique_labels):\n",
    "    labels_dict[target] = idx\n",
    "num_classes = len(labels_dict)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Costruzione lista dei label (stesso ordine della lista di file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5434"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_label_list = []\n",
    "for idx, value in train_df.iterrows():\n",
    "    example_label_list.append(labels_dict[value['target_label']])\n",
    "len(example_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(set(example_label_list))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "reducted_label_dict = {}\n",
    "for idx,value in enumerate(set(example_label_list)):\n",
    "    reducted_label_dict[value] = idx\n",
    "for idx,label in enumerate(example_label_list):\n",
    "    example_label_list[idx] = reducted_label_dict[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Transfer Learning\n",
    "Ripristino Inception v4 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwith tf.device('/gpu:0'):\\n    sampl_input = tf.placeholder(tf.float32, [None, 300,300, 3], name='incpetion_input_placeholder')\\n    #Invocazione della model fn per la definizione delle variabili della rete\\n    #Usa questi tensori che sono quelli per i quali passa il modello\\n    #Necessario per ripristinare il grafo\\n    print(inception_net_fn(sampl_input))\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "get_network_fn for returning the corresponding network function.\n",
    "\n",
    "Se num_classes è da cambiare, impostare is_training a True\n",
    "\n",
    "Ritorna la funzione definita nel corrispetivo file della rete\n",
    "'''\n",
    "model_name = 'inception_v4'\n",
    "inception_net_fn = nets_factory.get_network_fn(model_name,\n",
    "                                               num_classes=1001,\n",
    "                                               is_training = False\n",
    "                                              )\n",
    "'''\n",
    "with tf.device('/gpu:0'):\n",
    "    sampl_input = tf.placeholder(tf.float32, [None, 300,300, 3], name='incpetion_input_placeholder')\n",
    "    #Invocazione della model fn per la definizione delle variabili della rete\n",
    "    #Usa questi tensori che sono quelli per i quali passa il modello\n",
    "    #Necessario per ripristinare il grafo\n",
    "    print(inception_net_fn(sampl_input))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Input pipeline\n",
    "Definizione della input pipeline al modello TF\n",
    "\n",
    "<b>NB: La memoria della GPU non va MAI oltre i 100MB!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "#Serve per capire quando il generatore è passato a batch appartenenti a una nuova epoca \n",
    "BATCH_PER_EPOCH = np.ceil(len(example_file_list) / BATCH_SIZE)\n",
    "\n",
    "def parse_single_image(filename_queue):\n",
    "    #Dequeue a file name from the file name queue\n",
    "    #filename, y = filename_queue.dequeue()\n",
    "    #Non bisogna invocare il dequeue il parametro della funziona è già lo scodamento\n",
    "    filename, y = filename_queue[0], filename_queue[1]\n",
    "    #A y manca solo il one-hot\n",
    "    y = tf.one_hot(y, num_classes)\n",
    "    #Read image\n",
    "    raw = tf.read_file(filename)\n",
    "    #convert in jpg (in GPU!)\n",
    "    jpeg_image = tf.image.decode_jpeg(raw)\n",
    "    #Preprocessing with inception preprocessing\n",
    "    jpeg_image = inception_preprocessing.preprocess_image(jpeg_image, 300, 300, is_training=True)\n",
    "    return jpeg_image, y\n",
    "#jpeg_image = parse_single_image(filename_queue)\n",
    "\n",
    "def get_batch(filenames, labels, batch_size, num_epochs=None):\n",
    "    \n",
    "    #Coda lettura file, slice_input_producer accetta una lista di liste (stessa dimensione)\n",
    "    #Risultato dello scodamento è l'elemento corrente di ciascuna delle liste\n",
    "    #Le liste sono rispettivamente la lista di file e la lista dei label\n",
    "    filename_queue = tf.train.slice_input_producer([filenames, labels])\n",
    "    \n",
    "    #Lettura singolo record\n",
    "    jpeg_image,y = parse_single_image(filename_queue)\n",
    "    \n",
    "    # min_after_dequeue defines how big a buffer we will randomly sample\n",
    "    #   from -- bigger means better shuffling but slower start up and more\n",
    "    #   memory used.\n",
    "    # capacity must be larger than min_after_dequeue and the amount larger\n",
    "    #   determines the maximum we will prefetch.  Recommendation:\n",
    "    #   min_after_dequeue + (num_threads + a small safety margin) * batch_size\n",
    "    min_after_dequeue = 10\n",
    "    capacity = min_after_dequeue + 3 * batch_size\n",
    "    \n",
    "    #tensors è la lista dei tensori delle single feature e immagini. Esegue batch_size volte i tensori example e label per ottenere il batch\n",
    "    #num_threads incrementa effettivamente l'utilizzo della CPU (confermato dal throughput visisible sul cloudera manager,\n",
    "    #resta comunque un throughput lento ....\n",
    "    example_batch = tf.train.shuffle_batch(\n",
    "        tensors=[jpeg_image, y], batch_size=batch_size, capacity=capacity,\n",
    "        min_after_dequeue=min_after_dequeue, allow_smaller_final_batch=True, num_threads=2)\n",
    "    \n",
    "    return example_batch\n",
    "\n",
    "\n",
    "#TF Graph, per ora recupera solamente un batch\n",
    "with tf.device('/cpu:0'):\n",
    "    with tf.name_scope('preprocessing') as scope:\n",
    "        x,y = get_batch(example_file_list, example_label_list, batch_size=BATCH_SIZE)\n",
    "        #x = tf.contrib.layers.flatten(x)\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    #inception prelogits \n",
    "    inception_net_fn(x)\n",
    "    #prelogits = tf.placeholder(tf.float32, [None, 1536], name='prelogits_placeholder')\n",
    "    prelogits = tf.get_default_graph().get_tensor_by_name(\"InceptionV4/Logits/PreLogitsFlatten/Reshape:0\") \n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    with tf.variable_scope('trainable'):\n",
    "        '''with tf.variable_scope('hidden') as scope:\n",
    "            hidden = tf.layers.dense(\n",
    "                prelogits,\n",
    "                units=128,\n",
    "                activation=tf.nn.relu        \n",
    "            )'''\n",
    "\n",
    "        #Kenerl init None = glooroot initializers (sttdev = 1/sqrt(n))\n",
    "        with tf.variable_scope('readout') as scope:\n",
    "            output = tf.layers.dense(\n",
    "                prelogits,\n",
    "                units=num_classes,\n",
    "                activation=None\n",
    "            )\n",
    "\n",
    "    with tf.variable_scope('train_op') as scope:\n",
    "        # Define loss and optimizer\n",
    "        targetvars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"trainable\")\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost, var_list=targetvars)\n",
    "        # Accuracy\n",
    "        correct_pred = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "tf.summary.scalar('loss', cost)\n",
    "\n",
    "init = tf. global_variables_initializer()\n",
    "\n",
    "merged_summeries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current step: 0\n",
      "Loss: 2.5129287242889404 accuracy 0.1875\n",
      "Current step: 10\n",
      "Loss: 2.4275832176208496 accuracy 0.125\n",
      "Current step: 20\n",
      "Loss: 2.340498685836792 accuracy 0.1875\n",
      "Current step: 30\n",
      "Loss: 2.4241528511047363 accuracy 0.125\n",
      "Current step: 40\n",
      "Loss: 2.3813867568969727 accuracy 0.1875\n",
      "Current step: 50\n",
      "Loss: 2.468667507171631 accuracy 0.0625\n",
      "Current step: 60\n",
      "Loss: 2.4105844497680664 accuracy 0.0625\n",
      "Current step: 70\n",
      "Loss: 2.4713330268859863 accuracy 0.03125\n",
      "Current step: 80\n",
      "Loss: 2.482147693634033 accuracy 0.0625\n",
      "Current step: 90\n",
      "Loss: 2.4112768173217773 accuracy 0.09375\n",
      "Current step: 100\n",
      "Loss: 2.489518404006958 accuracy 0.0\n",
      "Current step: 110\n",
      "Loss: 2.445589542388916 accuracy 0.09375\n",
      "Current step: 120\n",
      "Loss: 2.6067144870758057 accuracy 0.09375\n",
      "Current step: 130\n",
      "Loss: 2.341503620147705 accuracy 0.21875\n",
      "Current step: 140\n",
      "Loss: 2.481048583984375 accuracy 0.0\n",
      "Current step: 150\n",
      "Loss: 2.4477105140686035 accuracy 0.09375\n",
      "Current step: 160\n",
      "Loss: 2.3633198738098145 accuracy 0.28125\n",
      "EPOCH 1\n",
      "Current step: 10\n",
      "Loss: 2.294314384460449 accuracy 0.21875\n",
      "Current step: 20\n",
      "Loss: 2.3068158626556396 accuracy 0.125\n",
      "Current step: 30\n",
      "Loss: 2.3125362396240234 accuracy 0.125\n",
      "Current step: 40\n",
      "Loss: 2.427682399749756 accuracy 0.0625\n",
      "Current step: 50\n",
      "Loss: 2.479543685913086 accuracy 0.0625\n",
      "Current step: 60\n",
      "Loss: 2.376668930053711 accuracy 0.09375\n",
      "Current step: 70\n",
      "Loss: 2.374061107635498 accuracy 0.15625\n",
      "Current step: 80\n",
      "Loss: 2.445662021636963 accuracy 0.125\n",
      "Current step: 90\n",
      "Loss: 2.4164578914642334 accuracy 0.125\n",
      "Current step: 100\n",
      "Loss: 2.4573426246643066 accuracy 0.0625\n",
      "Current step: 110\n",
      "Loss: 2.3238766193389893 accuracy 0.1875\n",
      "Current step: 120\n",
      "Loss: 2.460556983947754 accuracy 0.0\n",
      "Current step: 130\n",
      "Loss: 2.3908538818359375 accuracy 0.03125\n",
      "Current step: 140\n",
      "Loss: 2.3557121753692627 accuracy 0.15625\n",
      "Current step: 150\n",
      "Loss: 2.4666881561279297 accuracy 0.0625\n",
      "Current step: 160\n",
      "Loss: 2.379157781600952 accuracy 0.21875\n",
      "EPOCH 2\n",
      "Current step: 10\n",
      "Loss: 2.359149932861328 accuracy 0.0625\n",
      "Current step: 20\n",
      "Loss: 2.3096489906311035 accuracy 0.09375\n",
      "Current step: 30\n",
      "Loss: 2.355727434158325 accuracy 0.21875\n",
      "Current step: 40\n",
      "Loss: 2.3416519165039062 accuracy 0.25\n",
      "Current step: 50\n",
      "Loss: 2.3870017528533936 accuracy 0.1875\n",
      "Current step: 60\n",
      "Loss: 2.5441994667053223 accuracy 0.125\n",
      "Current step: 70\n",
      "Loss: 2.3084983825683594 accuracy 0.25\n",
      "Current step: 80\n",
      "Loss: 2.3421103954315186 accuracy 0.15625\n",
      "Current step: 90\n",
      "Loss: 2.2785158157348633 accuracy 0.15625\n",
      "Current step: 100\n",
      "Loss: 2.354095935821533 accuracy 0.21875\n",
      "Current step: 110\n",
      "Loss: 2.3940815925598145 accuracy 0.0625\n",
      "Current step: 120\n",
      "Loss: 2.3165218830108643 accuracy 0.25\n",
      "Current step: 130\n",
      "Loss: 2.4093031883239746 accuracy 0.125\n",
      "Current step: 140\n",
      "Loss: 2.2845211029052734 accuracy 0.1875\n",
      "Current step: 150\n",
      "Loss: 2.4306275844573975 accuracy 0.1875\n",
      "Current step: 160\n",
      "Loss: 2.368978261947632 accuracy 0.09375\n",
      "EPOCH 3\n",
      "Current step: 10\n",
      "Loss: 2.472738742828369 accuracy 0.125\n",
      "Current step: 20\n",
      "Loss: 2.427647590637207 accuracy 0.125\n",
      "Current step: 30\n",
      "Loss: 2.2375922203063965 accuracy 0.3125\n",
      "Current step: 40\n",
      "Loss: 2.3464789390563965 accuracy 0.1875\n",
      "Current step: 50\n",
      "Loss: 2.3891234397888184 accuracy 0.15625\n",
      "Current step: 60\n",
      "Loss: 2.335573196411133 accuracy 0.1875\n",
      "Current step: 70\n",
      "Loss: 2.3575267791748047 accuracy 0.0625\n",
      "Current step: 80\n",
      "Loss: 2.3571970462799072 accuracy 0.09375\n",
      "Current step: 90\n",
      "Loss: 2.2845168113708496 accuracy 0.09375\n",
      "Current step: 100\n",
      "Loss: 2.5006208419799805 accuracy 0.15625\n",
      "Current step: 110\n",
      "Loss: 2.280369281768799 accuracy 0.1875\n",
      "Current step: 120\n",
      "Loss: 2.3990046977996826 accuracy 0.125\n",
      "Current step: 130\n",
      "Loss: 2.3285584449768066 accuracy 0.125\n",
      "Current step: 140\n",
      "Loss: 2.426931858062744 accuracy 0.09375\n",
      "Current step: 150\n",
      "Loss: 2.415464401245117 accuracy 0.125\n",
      "Current step: 160\n",
      "Loss: 2.4257497787475586 accuracy 0.0625\n",
      "EPOCH 4\n",
      "Current step: 10\n",
      "Loss: 2.3156418800354004 accuracy 0.1875\n",
      "Current step: 20\n",
      "Loss: 2.364827871322632 accuracy 0.125\n",
      "Current step: 30\n",
      "Loss: 2.254568099975586 accuracy 0.21875\n",
      "Current step: 40\n",
      "Loss: 2.487118721008301 accuracy 0.03125\n",
      "Current step: 50\n",
      "Loss: 2.372596263885498 accuracy 0.09375\n",
      "Current step: 60\n",
      "Loss: 2.403766393661499 accuracy 0.09375\n",
      "Current step: 70\n",
      "Loss: 2.337301254272461 accuracy 0.1875\n",
      "Current step: 80\n",
      "Loss: 2.20710825920105 accuracy 0.25\n",
      "Current step: 90\n",
      "Loss: 2.234921932220459 accuracy 0.15625\n",
      "Current step: 100\n",
      "Loss: 2.398662567138672 accuracy 0.125\n",
      "Current step: 110\n",
      "Loss: 2.4561405181884766 accuracy 0.09375\n",
      "Current step: 120\n",
      "Loss: 2.3186514377593994 accuracy 0.1875\n",
      "Current step: 130\n",
      "Loss: 2.4015278816223145 accuracy 0.15625\n",
      "Current step: 140\n",
      "Loss: 2.374873399734497 accuracy 0.125\n",
      "Current step: 150\n",
      "Loss: 2.2621021270751953 accuracy 0.15625\n",
      "Current step: 160\n",
      "Loss: 2.344041585922241 accuracy 0.15625\n",
      "EPOCH 5\n",
      "Current step: 10\n",
      "Loss: 2.3828701972961426 accuracy 0.1875\n",
      "Current step: 20\n",
      "Loss: 2.304605722427368 accuracy 0.09375\n",
      "Current step: 30\n",
      "Loss: 2.376924514770508 accuracy 0.15625\n",
      "Current step: 40\n",
      "Loss: 2.2680609226226807 accuracy 0.25\n",
      "Current step: 50\n",
      "Loss: 2.322700023651123 accuracy 0.09375\n",
      "Current step: 60\n",
      "Loss: 2.366103172302246 accuracy 0.15625\n",
      "Current step: 70\n",
      "Loss: 2.211580514907837 accuracy 0.34375\n",
      "Current step: 80\n",
      "Loss: 2.3299784660339355 accuracy 0.0625\n",
      "Current step: 90\n",
      "Loss: 2.3758983612060547 accuracy 0.125\n",
      "Current step: 100\n",
      "Loss: 2.3659043312072754 accuracy 0.125\n",
      "Current step: 110\n",
      "Loss: 2.323573112487793 accuracy 0.15625\n",
      "Current step: 120\n",
      "Loss: 2.282770872116089 accuracy 0.25\n",
      "Current step: 130\n",
      "Loss: 2.3762335777282715 accuracy 0.1875\n",
      "Current step: 140\n",
      "Loss: 2.3269357681274414 accuracy 0.1875\n",
      "Current step: 150\n",
      "Loss: 2.3897228240966797 accuracy 0.0625\n",
      "Current step: 160\n",
      "Loss: 2.3257369995117188 accuracy 0.125\n",
      "EPOCH 6\n",
      "Current step: 10\n",
      "Loss: 2.354898452758789 accuracy 0.125\n",
      "Current step: 20\n",
      "Loss: 2.448961019515991 accuracy 0.28125\n",
      "Current step: 30\n",
      "Loss: 2.300652027130127 accuracy 0.09375\n",
      "Current step: 40\n",
      "Loss: 2.298259973526001 accuracy 0.125\n",
      "Current step: 50\n",
      "Loss: 2.3140764236450195 accuracy 0.1875\n",
      "Current step: 60\n",
      "Loss: 2.3086957931518555 accuracy 0.1875\n",
      "Current step: 70\n",
      "Loss: 2.2589874267578125 accuracy 0.25\n",
      "Current step: 80\n",
      "Loss: 2.2504522800445557 accuracy 0.25\n",
      "Current step: 90\n",
      "Loss: 2.348738670349121 accuracy 0.0625\n",
      "Current step: 100\n",
      "Loss: 2.3510100841522217 accuracy 0.1875\n",
      "Current step: 110\n",
      "Loss: 2.4643232822418213 accuracy 0.125\n",
      "Current step: 120\n",
      "Loss: 2.388218879699707 accuracy 0.125\n",
      "Current step: 130\n",
      "Loss: 2.311257839202881 accuracy 0.15625\n",
      "Current step: 140\n",
      "Loss: 2.293039321899414 accuracy 0.125\n",
      "Current step: 150\n",
      "Loss: 2.3351492881774902 accuracy 0.125\n",
      "Current step: 160\n",
      "Loss: 2.3422253131866455 accuracy 0.1875\n",
      "EPOCH 7\n",
      "Current step: 10\n",
      "Loss: 2.1799423694610596 accuracy 0.3125\n",
      "Current step: 20\n",
      "Loss: 2.362262010574341 accuracy 0.1875\n",
      "Current step: 30\n",
      "Loss: 2.303514003753662 accuracy 0.21875\n",
      "Current step: 40\n",
      "Loss: 2.3527729511260986 accuracy 0.21875\n",
      "Current step: 50\n",
      "Loss: 2.3132541179656982 accuracy 0.3125\n",
      "Current step: 60\n",
      "Loss: 2.435335636138916 accuracy 0.125\n",
      "Current step: 70\n",
      "Loss: 2.4095048904418945 accuracy 0.15625\n",
      "Current step: 80\n",
      "Loss: 2.3749773502349854 accuracy 0.125\n",
      "Current step: 90\n",
      "Loss: 2.3189139366149902 accuracy 0.28125\n",
      "Current step: 100\n",
      "Loss: 2.309497833251953 accuracy 0.1875\n",
      "Current step: 110\n",
      "Loss: 2.321743965148926 accuracy 0.25\n",
      "Current step: 120\n",
      "Loss: 2.2805705070495605 accuracy 0.1875\n",
      "Current step: 130\n",
      "Loss: 2.3229756355285645 accuracy 0.1875\n",
      "Current step: 140\n",
      "Loss: 2.268439769744873 accuracy 0.25\n",
      "Current step: 150\n",
      "Loss: 2.214064121246338 accuracy 0.28125\n",
      "Current step: 160\n",
      "Loss: 2.4231338500976562 accuracy 0.15625\n",
      "EPOCH 8\n",
      "Current step: 10\n",
      "Loss: 2.359771251678467 accuracy 0.09375\n",
      "Current step: 20\n",
      "Loss: 2.344373941421509 accuracy 0.15625\n",
      "Current step: 30\n",
      "Loss: 2.2594761848449707 accuracy 0.28125\n",
      "Current step: 40\n",
      "Loss: 2.378200054168701 accuracy 0.1875\n",
      "Current step: 50\n",
      "Loss: 2.2981276512145996 accuracy 0.25\n",
      "Current step: 60\n",
      "Loss: 2.28592586517334 accuracy 0.25\n",
      "Current step: 70\n",
      "Loss: 2.288090229034424 accuracy 0.21875\n",
      "Current step: 80\n",
      "Loss: 2.3732314109802246 accuracy 0.15625\n",
      "Current step: 90\n",
      "Loss: 2.439406394958496 accuracy 0.125\n",
      "Current step: 100\n",
      "Loss: 2.4344420433044434 accuracy 0.03125\n",
      "Current step: 110\n",
      "Loss: 2.3646481037139893 accuracy 0.21875\n",
      "Current step: 120\n",
      "Loss: 2.4472577571868896 accuracy 0.125\n",
      "Current step: 130\n",
      "Loss: 2.2674660682678223 accuracy 0.15625\n",
      "Current step: 140\n",
      "Loss: 2.2220616340637207 accuracy 0.25\n",
      "Current step: 150\n",
      "Loss: 2.273571729660034 accuracy 0.125\n",
      "Current step: 160\n",
      "Loss: 2.2972211837768555 accuracy 0.15625\n",
      "EPOCH 9\n",
      "Current step: 10\n",
      "Loss: 2.450946807861328 accuracy 0.0625\n",
      "Current step: 20\n",
      "Loss: 2.4767351150512695 accuracy 0.125\n",
      "Current step: 30\n",
      "Loss: 2.3627560138702393 accuracy 0.21875\n",
      "Current step: 40\n",
      "Loss: 2.2345151901245117 accuracy 0.15625\n",
      "Current step: 50\n",
      "Loss: 2.212468385696411 accuracy 0.3125\n",
      "Current step: 60\n",
      "Loss: 2.2985291481018066 accuracy 0.15625\n",
      "Current step: 70\n",
      "Loss: 2.294308662414551 accuracy 0.1875\n",
      "Current step: 80\n",
      "Loss: 2.212893009185791 accuracy 0.1875\n",
      "Current step: 90\n",
      "Loss: 2.238955020904541 accuracy 0.28125\n",
      "Current step: 100\n",
      "Loss: 2.2765023708343506 accuracy 0.15625\n",
      "Current step: 110\n",
      "Loss: 2.3384156227111816 accuracy 0.15625\n",
      "Current step: 120\n",
      "Loss: 2.226191997528076 accuracy 0.25\n",
      "Current step: 130\n",
      "Loss: 2.3575057983398438 accuracy 0.0625\n",
      "Current step: 140\n",
      "Loss: 2.402097225189209 accuracy 0.125\n",
      "Current step: 150\n",
      "Loss: 2.3285739421844482 accuracy 0.03125\n",
      "Current step: 160\n",
      "Loss: 2.277543306350708 accuracy 0.09375\n",
      "EPOCH 10\n",
      "Current step: 10\n",
      "Loss: 2.3629469871520996 accuracy 0.09375\n",
      "Current step: 20\n",
      "Loss: 2.286078691482544 accuracy 0.15625\n",
      "Current step: 30\n",
      "Loss: 2.2258248329162598 accuracy 0.25\n",
      "Current step: 40\n",
      "Loss: 2.4026131629943848 accuracy 0.09375\n",
      "Current step: 50\n",
      "Loss: 2.23561429977417 accuracy 0.21875\n",
      "Current step: 60\n",
      "Loss: 2.2282185554504395 accuracy 0.25\n",
      "Current step: 70\n",
      "Loss: 2.2993125915527344 accuracy 0.25\n",
      "Current step: 80\n",
      "Loss: 2.4143424034118652 accuracy 0.0625\n",
      "Current step: 90\n",
      "Loss: 2.3338499069213867 accuracy 0.1875\n",
      "Current step: 100\n",
      "Loss: 2.246335983276367 accuracy 0.0625\n",
      "Current step: 110\n",
      "Loss: 2.541498899459839 accuracy 0.15625\n",
      "Current step: 120\n",
      "Loss: 2.442999839782715 accuracy 0.09375\n",
      "Current step: 130\n",
      "Loss: 2.308549404144287 accuracy 0.1875\n",
      "Current step: 140\n",
      "Loss: 2.216637134552002 accuracy 0.34375\n",
      "Current step: 150\n",
      "Loss: 2.3202624320983887 accuracy 0.09375\n",
      "Current step: 160\n",
      "Loss: 2.3183093070983887 accuracy 0.21875\n",
      "EPOCH 11\n",
      "Current step: 10\n",
      "Loss: 2.402116298675537 accuracy 0.25\n",
      "Current step: 20\n",
      "Loss: 2.2492332458496094 accuracy 0.15625\n",
      "Current step: 30\n",
      "Loss: 2.3395819664001465 accuracy 0.1875\n",
      "Current step: 40\n",
      "Loss: 2.3580455780029297 accuracy 0.0625\n",
      "Current step: 50\n",
      "Loss: 2.3136253356933594 accuracy 0.09375\n",
      "Current step: 60\n",
      "Loss: 2.244309663772583 accuracy 0.21875\n",
      "Current step: 70\n",
      "Loss: 2.388603687286377 accuracy 0.1875\n",
      "Current step: 80\n",
      "Loss: 2.4558846950531006 accuracy 0.09375\n",
      "Current step: 90\n",
      "Loss: 2.354668140411377 accuracy 0.28125\n",
      "Current step: 100\n",
      "Loss: 2.2838611602783203 accuracy 0.1875\n",
      "Current step: 110\n",
      "Loss: 2.2936065196990967 accuracy 0.1875\n",
      "Current step: 120\n",
      "Loss: 2.3059029579162598 accuracy 0.15625\n",
      "Current step: 130\n",
      "Loss: 2.263805866241455 accuracy 0.1875\n",
      "Current step: 140\n",
      "Loss: 2.2682576179504395 accuracy 0.28125\n",
      "Current step: 150\n",
      "Loss: 2.323241949081421 accuracy 0.0625\n",
      "Current step: 160\n",
      "Loss: 2.1801295280456543 accuracy 0.25\n",
      "EPOCH 12\n",
      "Current step: 10\n",
      "Loss: 2.246455192565918 accuracy 0.25\n",
      "Current step: 20\n",
      "Loss: 2.202493190765381 accuracy 0.25\n",
      "Current step: 30\n",
      "Loss: 2.3593955039978027 accuracy 0.15625\n",
      "Current step: 40\n",
      "Loss: 2.27852463722229 accuracy 0.28125\n",
      "Current step: 50\n",
      "Loss: 2.1962804794311523 accuracy 0.1875\n",
      "Current step: 60\n",
      "Loss: 2.3841493129730225 accuracy 0.21875\n",
      "Current step: 70\n",
      "Loss: 2.3280534744262695 accuracy 0.09375\n",
      "Current step: 80\n",
      "Loss: 2.2271628379821777 accuracy 0.28125\n",
      "Current step: 90\n",
      "Loss: 2.315380811691284 accuracy 0.34375\n",
      "Current step: 100\n",
      "Loss: 2.3014025688171387 accuracy 0.125\n",
      "Current step: 110\n",
      "Loss: 2.293855667114258 accuracy 0.1875\n",
      "Current step: 120\n",
      "Loss: 2.2320992946624756 accuracy 0.21875\n",
      "Current step: 130\n",
      "Loss: 2.3359532356262207 accuracy 0.21875\n",
      "Current step: 140\n",
      "Loss: 2.1392955780029297 accuracy 0.3125\n",
      "Current step: 150\n",
      "Loss: 2.2693519592285156 accuracy 0.15625\n",
      "Current step: 160\n",
      "Loss: 2.2756972312927246 accuracy 0.25\n",
      "EPOCH 13\n",
      "Current step: 10\n",
      "Loss: 2.364438772201538 accuracy 0.125\n",
      "Current step: 20\n",
      "Loss: 2.1814565658569336 accuracy 0.15625\n",
      "Current step: 30\n",
      "Loss: 2.2269182205200195 accuracy 0.1875\n",
      "Current step: 40\n",
      "Loss: 2.2934517860412598 accuracy 0.1875\n",
      "Current step: 50\n",
      "Loss: 2.247753143310547 accuracy 0.15625\n",
      "Current step: 60\n",
      "Loss: 2.2071595191955566 accuracy 0.21875\n",
      "Current step: 70\n",
      "Loss: 2.3171863555908203 accuracy 0.25\n",
      "Current step: 80\n",
      "Loss: 2.2840576171875 accuracy 0.21875\n",
      "Current step: 90\n",
      "Loss: 2.306089401245117 accuracy 0.0625\n",
      "Current step: 100\n",
      "Loss: 2.358604669570923 accuracy 0.09375\n",
      "Current step: 110\n",
      "Loss: 2.1330206394195557 accuracy 0.21875\n",
      "Current step: 120\n",
      "Loss: 2.2403645515441895 accuracy 0.21875\n",
      "Current step: 130\n",
      "Loss: 2.33551025390625 accuracy 0.15625\n",
      "Current step: 140\n",
      "Loss: 2.220452308654785 accuracy 0.1875\n",
      "Current step: 150\n",
      "Loss: 2.2927963733673096 accuracy 0.25\n",
      "Current step: 160\n",
      "Loss: 2.296999454498291 accuracy 0.1875\n",
      "EPOCH 14\n",
      "Current step: 10\n",
      "Loss: 2.2636847496032715 accuracy 0.1875\n",
      "Current step: 20\n",
      "Loss: 2.3421075344085693 accuracy 0.15625\n",
      "Current step: 30\n",
      "Loss: 2.1184639930725098 accuracy 0.28125\n",
      "Current step: 40\n",
      "Loss: 2.3807973861694336 accuracy 0.125\n",
      "Current step: 50\n",
      "Loss: 2.3892171382904053 accuracy 0.21875\n",
      "Current step: 60\n",
      "Loss: 2.2767868041992188 accuracy 0.25\n",
      "Current step: 70\n",
      "Loss: 2.1882028579711914 accuracy 0.21875\n",
      "Current step: 80\n",
      "Loss: 2.2089591026306152 accuracy 0.28125\n",
      "Current step: 90\n",
      "Loss: 2.2852425575256348 accuracy 0.28125\n",
      "Current step: 100\n",
      "Loss: 2.2170445919036865 accuracy 0.34375\n",
      "Current step: 110\n",
      "Loss: 2.277245044708252 accuracy 0.25\n",
      "Current step: 120\n",
      "Loss: 2.4141268730163574 accuracy 0.1875\n",
      "Current step: 130\n",
      "Loss: 2.3300564289093018 accuracy 0.21875\n",
      "Current step: 140\n",
      "Loss: 2.1189913749694824 accuracy 0.375\n",
      "Current step: 150\n",
      "Loss: 2.0822830200195312 accuracy 0.3125\n",
      "Current step: 160\n",
      "Loss: 2.196434736251831 accuracy 0.1875\n",
      "EPOCH 15\n",
      "Current step: 10\n",
      "Loss: 2.4302244186401367 accuracy 0.09375\n",
      "Current step: 20\n",
      "Loss: 2.410517454147339 accuracy 0.125\n",
      "Current step: 30\n",
      "Loss: 2.442936897277832 accuracy 0.0\n",
      "Current step: 40\n",
      "Loss: 2.2618093490600586 accuracy 0.21875\n",
      "Current step: 50\n",
      "Loss: 2.225010395050049 accuracy 0.25\n",
      "Current step: 60\n",
      "Loss: 2.366292953491211 accuracy 0.0625\n",
      "Current step: 70\n",
      "Loss: 2.2814345359802246 accuracy 0.03125\n",
      "Current step: 80\n",
      "Loss: 2.2059459686279297 accuracy 0.25\n",
      "Current step: 90\n",
      "Loss: 2.3246161937713623 accuracy 0.25\n",
      "Current step: 100\n",
      "Loss: 2.2415621280670166 accuracy 0.1875\n",
      "Current step: 110\n",
      "Loss: 2.3221468925476074 accuracy 0.15625\n",
      "Current step: 120\n",
      "Loss: 2.1420323848724365 accuracy 0.3125\n",
      "Current step: 130\n",
      "Loss: 2.262669324874878 accuracy 0.21875\n",
      "Current step: 140\n",
      "Loss: 2.2032644748687744 accuracy 0.21875\n",
      "Current step: 150\n",
      "Loss: 2.3280534744262695 accuracy 0.1875\n",
      "Current step: 160\n",
      "Loss: 2.3078768253326416 accuracy 0.28125\n",
      "EPOCH 16\n",
      "Current step: 10\n",
      "Loss: 2.3515615463256836 accuracy 0.21875\n",
      "Current step: 20\n",
      "Loss: 2.36397123336792 accuracy 0.1875\n",
      "Current step: 30\n",
      "Loss: 2.1354308128356934 accuracy 0.3125\n",
      "Current step: 40\n",
      "Loss: 2.353476047515869 accuracy 0.0625\n",
      "Current step: 50\n",
      "Loss: 2.212703227996826 accuracy 0.25\n",
      "Current step: 60\n",
      "Loss: 2.308811664581299 accuracy 0.1875\n",
      "Current step: 70\n",
      "Loss: 2.2962093353271484 accuracy 0.25\n",
      "Current step: 80\n",
      "Loss: 2.425044059753418 accuracy 0.09375\n",
      "Current step: 90\n",
      "Loss: 2.1793198585510254 accuracy 0.25\n",
      "Current step: 100\n",
      "Loss: 2.1629090309143066 accuracy 0.3125\n",
      "Current step: 110\n",
      "Loss: 2.359266757965088 accuracy 0.25\n",
      "Current step: 120\n",
      "Loss: 2.3109078407287598 accuracy 0.1875\n",
      "Current step: 130\n",
      "Loss: 2.3592312335968018 accuracy 0.25\n",
      "Current step: 140\n",
      "Loss: 2.1329619884490967 accuracy 0.21875\n",
      "Current step: 150\n",
      "Loss: 2.26998233795166 accuracy 0.125\n",
      "Current step: 160\n",
      "Loss: 2.156911611557007 accuracy 0.21875\n",
      "EPOCH 17\n",
      "Current step: 10\n",
      "Loss: 2.22196364402771 accuracy 0.1875\n",
      "Current step: 20\n",
      "Loss: 2.339437484741211 accuracy 0.125\n",
      "Current step: 30\n",
      "Loss: 2.3673462867736816 accuracy 0.1875\n",
      "Current step: 40\n",
      "Loss: 2.4124598503112793 accuracy 0.125\n",
      "Current step: 50\n",
      "Loss: 2.257690906524658 accuracy 0.3125\n",
      "Current step: 60\n",
      "Loss: 2.302187204360962 accuracy 0.15625\n",
      "Current step: 70\n",
      "Loss: 2.139050006866455 accuracy 0.28125\n",
      "Current step: 80\n",
      "Loss: 2.273402214050293 accuracy 0.28125\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: preprocessing/input_producer/input_producer/input_producer_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](preprocessing/input_producer/input_producer, preprocessing/input_producer/input_producer/RandomShuffle)]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5e3fbecdf23f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#inception_pre_logits = sess.run(tf.get_default_graph().get_tensor_by_name(\"InceptionV4/Logits/PreLogitsFlatten/Reshape:0\"),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m          \u001b[0;31m#feed_dict={sampl_input: x_batch})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;31m#print(x_batch.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcurrent_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#GPU config\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "#Saver per restoring inception net\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter(TRAINING_CHECKPOINT_DIR,\n",
    "                                   sess.graph)\n",
    "    #Start populating the filename queue.\n",
    "    coord = tf.train.Coordinator()\n",
    "    #Senza questa chiamata non partono i thread per popolare la coda che permette di eseguire la read\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    #Current epoch and step servono a capire quando cambiare epoca e quando fermarsi\n",
    "    current_epoch = 0\n",
    "    current_step = 0\n",
    "    while current_epoch < EPOCHS: \n",
    "        x_batch, y_batch = sess.run([x,y])\n",
    "        #Forward pass nella incpetion net\n",
    "        #inception_pre_logits = sess.run(tf.get_default_graph().get_tensor_by_name(\"InceptionV4/Logits/PreLogitsFlatten/Reshape:0\"),\n",
    "         #feed_dict={sampl_input: x_batch})\n",
    "        sess.run(optimizer, feed_dict={x: x_batch, y: y_batch})\n",
    "        #print(x_batch.shape)\n",
    "        if current_step % 10 == 0:\n",
    "            #print(\"Batch shape {}\".format(x_batch.shape))\n",
    "            print(\"Current step: {0}\".format(current_step))\n",
    "            train_loss, train_accuracy, train_summ  = sess.run([cost,accuracy,merged_summeries],\n",
    "                                                               feed_dict={x: x_batch, y: y_batch})\n",
    "            print(\"Loss: {0} accuracy {1}\".format(train_loss, train_accuracy))\n",
    "            writer.add_summary(train_summ, current_epoch * current_step + 1)\n",
    "        #Cambiare epoca, raggiunto il massimo per l'epoca corrente\n",
    "        if current_step == (BATCH_PER_EPOCH - 1):\n",
    "            current_epoch += 1\n",
    "            current_step = 0\n",
    "            print(\"EPOCH {0}\".format(current_epoch))\n",
    "        #Epoche terminate -> chiudere\n",
    "        if current_epoch >= EPOCHS:\n",
    "            break\n",
    "\n",
    "        if current_step == 0 and current_epoch == 0:\n",
    "            writer.add_graph(sess.graph)\n",
    "        #train_summary = sess.run([merged_summeries], feed_dict={x: x_batch, y: y_batch})\n",
    "        #writer.add_summary(train_summary, current_step)\n",
    "        current_step +=  1\n",
    "    #for i in range(10):\n",
    "        #converted_im = sess.run(jpeg_image)\n",
    "        #print(converted_im.shape)\n",
    "        \n",
    "    #Chiusura del coordinator (chiudi i thread di lettura)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'trainable/dense/kernel:0' shape=(1536, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'trainable/dense/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'trainable/dense_1/kernel:0' shape=(128, 6) dtype=float32_ref>,\n",
       " <tf.Variable 'trainable/dense_1/bias:0' shape=(6,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"trainable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
